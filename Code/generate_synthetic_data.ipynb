{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126f922a-69ce-4408-9095-589a9073c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: ctgan in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.29 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from ctgan) (4.66.4)\n",
      "Requirement already satisfied: rdt>=1.11.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from ctgan) (1.13.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from ctgan) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from ctgan) (2.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from ctgan) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas>=1.5.0->ctgan) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas>=1.5.0->ctgan) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas>=1.5.0->ctgan) (2023.3)\n",
      "Requirement already satisfied: Faker>=17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from rdt>=1.11.0->ctgan) (30.3.0)\n",
      "Requirement already satisfied: scipy>=1.9.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from rdt>=1.11.0->ctgan) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from rdt>=1.11.0->ctgan) (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=2.0.0->ctgan) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm<5,>=4.29->ctgan) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->ctgan) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn>=1.1.3->rdt>=1.11.0->ctgan) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn>=1.1.3->rdt>=1.11.0->ctgan) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->torch>=2.0.0->ctgan) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from sympy->torch>=2.0.0->ctgan) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install ctgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abe689c-94b9-4af1-a8da-12564abc3c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Code</th>\n",
       "      <th>Activity_Type</th>\n",
       "      <th>Heart rate___beats/minute</th>\n",
       "      <th>Calories burned_kcal</th>\n",
       "      <th>Exercise duration_s</th>\n",
       "      <th>Sleep type duration_minutes</th>\n",
       "      <th>Sleep duration_minutes</th>\n",
       "      <th>Floors climbed___floors</th>\n",
       "      <th>Patient ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022=12-08 14:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Physical Activity</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022=12-08 21:05</td>\n",
       "      <td>LA11836-6</td>\n",
       "      <td>Running</td>\n",
       "      <td>156.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022=12-08 22:01</td>\n",
       "      <td>LA11836-6</td>\n",
       "      <td>Running</td>\n",
       "      <td>170.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44878.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022=12-08 22:06</td>\n",
       "      <td>LA11836-6</td>\n",
       "      <td>Running</td>\n",
       "      <td>166.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21497.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022=12-08 22:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Physical Activity</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>User0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Datetime       Code         Activity_Type  \\\n",
       "0  2022=12-08 14:17        NaN  No Physical Activity   \n",
       "1  2022=12-08 21:05  LA11836-6               Running   \n",
       "2  2022=12-08 22:01  LA11836-6               Running   \n",
       "3  2022=12-08 22:06  LA11836-6               Running   \n",
       "4  2022=12-08 22:16        NaN  No Physical Activity   \n",
       "\n",
       "   Heart rate___beats/minute  Calories burned_kcal  Exercise duration_s  \\\n",
       "0                       72.0                   NaN                  NaN   \n",
       "1                      156.0                  20.0              40851.0   \n",
       "2                      170.0                  30.0              44878.0   \n",
       "3                      166.0                  20.0              21497.0   \n",
       "4                       78.0                   NaN                  NaN   \n",
       "\n",
       "   Sleep type duration_minutes  Sleep duration_minutes  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "3                          NaN                     NaN   \n",
       "4                          NaN                     NaN   \n",
       "\n",
       "   Floors climbed___floors Patient ID  \n",
       "0                      NaN      User0  \n",
       "1                      NaN      User0  \n",
       "2                      NaN      User0  \n",
       "3                      NaN      User0  \n",
       "4                      NaN      User0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the CSV file into a pandas DataFrame using the given local file path.\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'combined_synthetic_data_with_patient_ids.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "combined_df = pd.read_csv(file_path)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd3bd35-ea95-4c40-8275-0069b2a3824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fd\\AppData\\Local\\Temp\\ipykernel_41324\\664360208.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df['Activity_Type'] = combined_df['Activity_Type'].replace(activity_mapping)\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\autograd\\graph.py:768: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activity_Type  Heart rate___beats/minute  Sleep type duration_minutes  \\\n",
      "0   Light Sleep                         55                            6   \n",
      "1   Light Sleep                         66                           13   \n",
      "2   Light Sleep                         79                            6   \n",
      "3   Light Sleep                         79                           13   \n",
      "4   Light Sleep                         80                            9   \n",
      "\n",
      "   Sleep duration_minutes  Calories burned_kcal  Exercise duration_s  \\\n",
      "0                      10                  <NA>                 <NA>   \n",
      "1                      33                  <NA>                 <NA>   \n",
      "2                      32                  <NA>                 <NA>   \n",
      "3                      36                  <NA>                 <NA>   \n",
      "4                      13                  <NA>                 <NA>   \n",
      "\n",
      "   Floors climbed___floors     Code  \n",
      "0                     <NA>  93830-8  \n",
      "1                     <NA>  93830-8  \n",
      "2                     <NA>  93830-8  \n",
      "3                     <NA>  93830-8  \n",
      "4                     <NA>  93830-8  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "import numpy as np\n",
    "\n",
    "# Load the real dataset (combined_df should already exist from previous steps)\n",
    "\n",
    "# Define the mapping dictionary for activity types\n",
    "activity_mapping = {\n",
    "    'Light Sleep': 1,\n",
    "    'No Physical Activity': 2,\n",
    "    'Running': 3,\n",
    "    'Floors Climbed': 4,\n",
    "    'REM Sleep': 5,\n",
    "    'Walking': 6\n",
    "}\n",
    "\n",
    "# Replace the 'Activity_Type' values based on the mapping dictionary\n",
    "combined_df['Activity_Type'] = combined_df['Activity_Type'].replace(activity_mapping)\n",
    "\n",
    "# Retain Activity_Type in the filtered data\n",
    "df_1_5 = combined_df[combined_df['Activity_Type'].isin([1, 5])][[\n",
    "    'Activity_Type', 'Heart rate___beats/minute', 'Sleep type duration_minutes', 'Sleep duration_minutes'\n",
    "]].dropna()\n",
    "\n",
    "df_3_6 = combined_df[combined_df['Activity_Type'].isin([3, 6])][[\n",
    "    'Activity_Type', 'Heart rate___beats/minute', 'Calories burned_kcal', 'Exercise duration_s'\n",
    "]].dropna()\n",
    "\n",
    "df_2 = combined_df[combined_df['Activity_Type'] == 2][[\n",
    "    'Activity_Type', 'Heart rate___beats/minute'\n",
    "]].dropna()\n",
    "\n",
    "df_4 = combined_df[combined_df['Activity_Type'] == 4][[\n",
    "    'Activity_Type', 'Heart rate___beats/minute', 'Floors climbed___floors'\n",
    "]].dropna()\n",
    "\n",
    "# Helper function to train and generate synthetic data using CTGAN\n",
    "def generate_synthetic_data(real_data, num_samples):\n",
    "    ctgan = CTGAN()\n",
    "    ctgan.fit(real_data, epochs=100)\n",
    "    synthetic_data = ctgan.sample(num_samples)\n",
    "    return synthetic_data\n",
    "\n",
    "# Generate synthetic data for each subset\n",
    "synthetic_df_1_5 = generate_synthetic_data(df_1_5, num_samples=10000)\n",
    "synthetic_df_3_6 = generate_synthetic_data(df_3_6, num_samples=10000)\n",
    "synthetic_df_2 = generate_synthetic_data(df_2, num_samples=10000)\n",
    "synthetic_df_4 = generate_synthetic_data(df_4, num_samples=10000)\n",
    "\n",
    "# Combine all the generated synthetic data\n",
    "synthetic_combined_df = pd.concat([synthetic_df_1_5, synthetic_df_3_6, synthetic_df_2, synthetic_df_4], ignore_index=True)\n",
    "\n",
    "# Convert the relevant columns to integer (keeping only the integer part)\n",
    "cols_to_convert = ['Heart rate___beats/minute', 'Sleep type duration_minutes', 'Sleep duration_minutes',\n",
    "                   'Calories burned_kcal', 'Exercise duration_s', 'Floors climbed___floors']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    if col in synthetic_combined_df.columns:\n",
    "        synthetic_combined_df[col] = np.floor(synthetic_combined_df[col]).astype('Int64')  # Keep only integer part\n",
    "\n",
    "# Ensure 'Floors climbed___floors' is always 1 for \"Floors Climbed\" activity\n",
    "synthetic_combined_df.loc[synthetic_combined_df['Activity_Type'] == 'Floors Climbed', 'Floors climbed___floors'] = 1\n",
    "\n",
    "# Reverse the mapping to convert Activity_Type back to original string values\n",
    "reverse_activity_mapping = {\n",
    "    1: 'Light Sleep',\n",
    "    2: 'No Physical Activity',\n",
    "    3: 'Running',\n",
    "    4: 'Floors Climbed',\n",
    "    5: 'REM Sleep',\n",
    "    6: 'Walking'\n",
    "}\n",
    "\n",
    "synthetic_combined_df['Activity_Type'] = synthetic_combined_df['Activity_Type'].replace(reverse_activity_mapping)\n",
    "\n",
    "# Define the mapping for the Code column\n",
    "code_mapping = {\n",
    "    'Light Sleep': '93830-8',\n",
    "    'No Physical Activity': '',\n",
    "    'Running': 'LA11836-6',\n",
    "    'Floors Climbed': '',\n",
    "    'REM Sleep': '93829-0',\n",
    "    'Walking': '370'\n",
    "}\n",
    "\n",
    "# Add the Code column to the DataFrame\n",
    "synthetic_combined_df['Code'] = synthetic_combined_df['Activity_Type'].map(code_mapping)\n",
    "\n",
    "# Show the final synthetic data with original Activity_Type values and Code\n",
    "print(synthetic_combined_df.head())\n",
    "\n",
    "# Save the synthetic data to a CSV file\n",
    "synthetic_combined_df.to_csv('synthetic_data_with_activity_type.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a8d609-b62b-4130-9a61-4d805b54ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime  Activity_Type\n",
      "0 2022-12-08 00:48:00              4\n",
      "1 2022-12-08 01:47:00              1\n",
      "2 2022-12-08 01:53:00              5\n",
      "3 2022-12-08 02:39:00              1\n",
      "4 2022-12-08 04:37:00              4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "def generate_synthetic_data(combined_df, start_date, end_date, num_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic datetime and activity type data based on the original distribution.\n",
    "\n",
    "    Parameters:\n",
    "        combined_df (pd.DataFrame): Original DataFrame containing 'Datetime' and 'Activity_Type' columns.\n",
    "        start_date (str or pd.Timestamp): The start date for generating synthetic datetime values.\n",
    "        end_date (str or pd.Timestamp): The end date for generating synthetic datetime values.\n",
    "        num_samples (int): The number of synthetic samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        synthetic_df (pd.DataFrame): A DataFrame containing synthetic 'Datetime' and 'Activity_Type' columns.\n",
    "    \"\"\"\n",
    "    # Step 1: Convert 'Datetime' to a string if it's not already in string format\n",
    "    if combined_df['Datetime'].dtype != 'object':\n",
    "        combined_df['Datetime'] = combined_df['Datetime'].astype(str)\n",
    "\n",
    "    # Step 2: Replace '=' with '-' in the 'Datetime' strings\n",
    "    combined_df['Datetime'] = combined_df['Datetime'].str.replace('=', '-', regex=False)\n",
    "\n",
    "    # Step 3: Convert the cleaned 'Datetime' column back to a proper datetime object\n",
    "    combined_df['Datetime'] = pd.to_datetime(combined_df['Datetime'], errors='coerce')\n",
    "\n",
    "    # Step 4: Extract hour and minute, convert to total minutes of the day\n",
    "    combined_df['Hour'] = combined_df['Datetime'].dt.hour\n",
    "    combined_df['Minute'] = combined_df['Datetime'].dt.minute\n",
    "    combined_df['Minutes_of_Day'] = combined_df['Hour'] * 60 + combined_df['Minute']\n",
    "\n",
    "    # Step 5: Learn the distribution of 'Minutes_of_Day'\n",
    "    minutes_distribution = combined_df['Minutes_of_Day'].value_counts(normalize=True)\n",
    "\n",
    "    # Step 6: Generate similar 'Minutes_of_Day' values based on the learned distribution\n",
    "    def generate_similar_minutes_of_day():\n",
    "        return np.random.choice(minutes_distribution.index, p=minutes_distribution.values)\n",
    "\n",
    "    # Generate random 'Minutes_of_Day' values based on the distribution\n",
    "    random_minutes_of_day = [generate_similar_minutes_of_day() for _ in range(num_samples)]\n",
    "\n",
    "    # Convert the generated 'Minutes_of_Day' back to hours and minutes\n",
    "    generated_hours = [int(minute // 60) for minute in random_minutes_of_day]  # Ensure conversion to int\n",
    "    generated_minutes = [int(minute % 60) for minute in random_minutes_of_day]  # Ensure conversion to int\n",
    "\n",
    "    # Step 7: Generate random dates within the provided date range\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    def random_date(start, end):\n",
    "        return start + timedelta(days=random.randint(0, (end - start).days))\n",
    "\n",
    "    random_dates = [random_date(start_date, end_date) for _ in range(num_samples)]\n",
    "\n",
    "    # Combine the random dates with the generated hours and minutes to form new Datetime values\n",
    "    generated_datetimes = [pd.Timestamp(date) + timedelta(hours=int(hour), minutes=int(minute))\n",
    "                           for date, hour, minute in zip(random_dates, generated_hours, generated_minutes)]\n",
    "\n",
    "    # Step 8: Sort the generated datetimes in ascending order\n",
    "    generated_datetimes_sorted = sorted(generated_datetimes)\n",
    "\n",
    "    # Step 9: Learn the distribution of 'Activity_Type' from the original dataset\n",
    "    activity_distribution = combined_df['Activity_Type'].value_counts(normalize=True)\n",
    "\n",
    "    # Step 10: Generate 'Activity_Type' values based on the distribution\n",
    "    def generate_activity_type():\n",
    "        return np.random.choice(activity_distribution.index, p=activity_distribution.values)\n",
    "\n",
    "    generated_activity_types = [generate_activity_type() for _ in range(num_samples)]\n",
    "\n",
    "    # Step 11: Create a DataFrame to store the sorted Datetime and corresponding Activity_Type values\n",
    "    synthetic_df = pd.DataFrame({\n",
    "        'Datetime': generated_datetimes_sorted,\n",
    "        'Activity_Type': generated_activity_types\n",
    "    })\n",
    "\n",
    "    return synthetic_df\n",
    "\n",
    "# Example usage:\n",
    "# combined_df = ...  # Load or create your DataFrame here\n",
    "synthetic_data = generate_synthetic_data(combined_df, \"2022-12-08\", \"2022-12-30\", 380)\n",
    "print(synthetic_data.head())\n",
    "synthetic_data.to_csv('synthetic_data_with_datetime_and_activity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30ba1da-a7eb-40d0-8a78-9e1a7ebf18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Datetime     Code   Activity_Type  Heart rate___beats/minute  \\\n",
      "0  2022-12-08 00:48:00      NaN  Floors Climbed                         67   \n",
      "1  2022-12-08 01:47:00  93830-8     Light Sleep                         49   \n",
      "2  2022-12-08 01:53:00  93829-0       REM Sleep                         54   \n",
      "3  2022-12-08 02:39:00  93830-8     Light Sleep                         80   \n",
      "4  2022-12-08 04:37:00      NaN  Floors Climbed                         64   \n",
      "\n",
      "   Calories burned_kcal  Exercise duration_s  Sleep duration_minutes  \\\n",
      "0                   NaN                  NaN                     NaN   \n",
      "1                   NaN                  NaN                     9.0   \n",
      "2                   NaN                  NaN                     4.0   \n",
      "3                   NaN                  NaN                    34.0   \n",
      "4                   NaN                  NaN                     NaN   \n",
      "\n",
      "   Sleep type duration_minutes  Floors climbed___floors  \n",
      "0                          NaN                      0.0  \n",
      "1                          7.0                      NaN  \n",
      "2                          2.0                      NaN  \n",
      "3                         11.0                      NaN  \n",
      "4                          NaN                      0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "synthetic_data_with_datetime = pd.read_csv('synthetic_data_with_datetime_and_activity.csv')\n",
    "synthetic_data_with_activity_type = pd.read_csv('synthetic_data_with_activity_type.csv')\n",
    "\n",
    "# Define the reverse activity mapping\n",
    "reverse_activity_mapping = {\n",
    "    1: 'Light Sleep',\n",
    "    2: 'No Physical Activity',\n",
    "    3: 'Running',\n",
    "    4: 'Floors Climbed',\n",
    "    5: 'REM Sleep',\n",
    "    6: 'Walking'\n",
    "}\n",
    "\n",
    "# Map Activity_Type in datetime DataFrame to activity names\n",
    "synthetic_data_with_datetime['Activity_Type'] = synthetic_data_with_datetime['Activity_Type'].replace(reverse_activity_mapping)\n",
    "\n",
    "# Step 3: For each row in synthetic_data_with_datetime, randomly select a row from synthetic_data_with_activity_type\n",
    "new_rows = []\n",
    "\n",
    "for index, row in synthetic_data_with_datetime.iterrows():\n",
    "    activity = row['Activity_Type']\n",
    "    \n",
    "    # Find rows in synthetic_data_with_activity_type that match the current activity\n",
    "    matching_rows = synthetic_data_with_activity_type[synthetic_data_with_activity_type['Activity_Type'] == activity]\n",
    "    \n",
    "    if not matching_rows.empty:\n",
    "        # Randomly select one row from matching_rows\n",
    "        random_row = matching_rows.sample(n=1).iloc[0]\n",
    "        \n",
    "        # Create a new row by combining the datetime row with the randomly selected activity type row\n",
    "        new_row = {**row, **random_row}\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Create a new DataFrame from the new rows\n",
    "final_combined_data = pd.DataFrame(new_rows)\n",
    "\n",
    "# Reorder the columns as specified\n",
    "column_order = [\n",
    "    'Datetime', \n",
    "    'Code', \n",
    "    'Activity_Type', \n",
    "    'Heart rate___beats/minute', \n",
    "    'Calories burned_kcal', \n",
    "    'Exercise duration_s', \n",
    "    'Sleep duration_minutes', \n",
    "    'Sleep type duration_minutes', \n",
    "    'Floors climbed___floors'\n",
    "]\n",
    "\n",
    "final_combined_data = final_combined_data[column_order]\n",
    "\n",
    "# Step 5: Save the final DataFrame to a new CSV file\n",
    "final_combined_data.to_csv('Synthetic_User1.csv', index=False)\n",
    "\n",
    "# Display the head of the final DataFrame\n",
    "print(final_combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2696700-0cb7-4b38-9b4c-4c6b8d669fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
